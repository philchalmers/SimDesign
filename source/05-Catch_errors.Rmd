%\VignetteIndexEntry{SimDesign}
%\VignetteEngine{knitr::knitr}
---
title: "SimDesign"
author: "Phil Chalmers"
date: "September 22, 2015"
output:
  html_document:
    number_sections: yes
    toc: yes
---

```{r include=FALSE}
options(digits = 3)
```

# Catch Errors

Error catching is an important thing to consider when creating Monte Carlo simulations. Sometimes, iterative algorithms will 'fail to converge' or crash for other reasons (e.g., sparse data). This is why wrapping sensitive functions in a `try()` block is so important. Below we demonstrate what happens when errors are thrown and caught, and how this information is tracked in the returned object.

### Define the functions

As usual, define the functions of interest. 

```{r}
library(SimDesign)
# SimDesign_functions()

Design <- data.frame(N = c(10,20,30))
```

```{r}
Generate <- function(condition, fixed_design_elements = NULL) {
    ret <- rnorm(condition$N)    
    ret
}

Analyse <- function(condition, dat, fixed_design_elements = NULL, parameters = NULL) {
    whc <- sample(c(0,1,2,3), 1, prob = c(.7, .20, .05, .05))
    if(whc == 0){
       ret <- try(mean(dat), silent=TRUE)
    } else if(whc == 1){
        ret <- try(t.test(), silent=TRUE) # missing arguments
    } else if(whc == 2){
        # invalid arguments, but error thrown by check_error()
        ret <- try(suppressWarnings(t.test('invalid')), silent=TRUE) 
        check_error(ret)
    } else if(whc == 3){
        stop('Manual error thrown', call.=FALSE) # throw error manually
    }
    ret
}

Summarise <- function(condition, results, fixed_design_elements = NULL, parameters_list = NULL) {
    ret <- c(bias = bias(results, 0))
    ret
}
```

The above simulation is just an example of how errors may be caught with `try()` blocks or manually thrown with the `stop()` or `check_error()` functions. 

### Run the simulation

```{r cache=TRUE}
set.seed(1)
result <- runSimulation(Design, replications = 100, 
                       generate=Generate, analyse=Analyse, summarise=Summarise)
```

```{r}
print(result)
```

What you'll immediately notice from this output object is that the name of the error thrown, and the function from which the error was thrown, are appended as additional columns in the output with the prefix `TRY_ERROR_MESSAGE: `. Furthermore, the frequency in which the error occurred are also included for each design condition (here the `t.test.default()` error, where no inputs were supplied, occurred more often than the manually thrown error as well as the invalid-input error thrown by `check_error()`). 

The `check_error()` function, however, has the added benifit that it can throw errors for multiple input objects. Therefore, passing something like `check_error(mod1, mod2, mod3)` will throw a stuitable stop message
if any of the objects have witnessed an error.

### What to do

If errors occur too often then these design conditions should either be extracted out of the simulation or further inspected to determine if they can be fixed (e.g., providing better starting values, increasing convergence criteria/number of iterations, etc). The use of the debugging features may be useful to track
down issues here as well. For example, add the line `if(is(object, 'try-error')) browser()` to jump into the location/replication where the object unexpectedly witnessed an error, and try to disern why the error occured.
